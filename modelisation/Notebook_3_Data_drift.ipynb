{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data drift P7\n",
    "- Analyse : du data drift de la TARGET et des features sur le dataset Credit Risk\n",
    "- Objectif : détecter 1 dérive (variation importante) dans le comportement des clients\n",
    "- Moyen : analyse de la différence dans la distribution statistique de chaque variable entre les données de référence et les données courantes via le package EVIDENTLY "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import re # Traitement des caractères spéciaux\n",
    "\n",
    "# Pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Evidently for data drif reports\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "\n",
    "#from evidently.dashboard import Dashboard\n",
    "#from evidently.dashboard.tabs import Dashboard\n",
    "#from evidently.metrics import *\n",
    "\n",
    "#from evidently.dashboard.tabs import DataDriftTab, CatTargetDriftTab\n",
    "#from evidently.model_profile import Profile\n",
    "#from evidently.profile_sections import DataDriftProfileSection, CatTargetDriftProfileSection\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions : (356251, 803)\n"
     ]
    }
   ],
   "source": [
    "# Lecture du fichier des data de Risque crédit pré traités\n",
    "df = pd.read_csv('df_scenario_0.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(f'Dimensions : {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de nettoyage des NaN du dataset\n",
    "# Nettoyage des valeurs NaN et des noms de colonnes contenant des caractères spéciaux\n",
    "# Fill NaN --> 0 : correspond aux valeurs sans correspondance dans les jointures gauche (left join)\n",
    "def fct_clean_data(df):\n",
    "    # Fill NaN par 0\n",
    "    feat = [v for v in list(df.columns) if v != 'TARGET']\n",
    "    df[feat] = df[feat].fillna(0, axis=0)\n",
    "\n",
    "    # Bug : \"[LightGBM] Do not support special JSON characters in feature name\"\n",
    "    # Correction : suppression des caractères spéciaux ' ', ','... dans le nom des colonnes\n",
    "    new_names = {col: re.sub(r'[^A-Za-z0-9_]+', '', col) for col in df.columns}\n",
    "    new_names_list = list(new_names.values())\n",
    "    \n",
    "    # Nom des colonnes unique : ajout du suffix i si le nom de la colonne apparaît plus d'1 fois après suppression des caractères spéciaux\n",
    "    new_names = {col: f'{new_col}_{i}' if new_col in new_names_list[:i] else new_col for i, (col, new_col) in enumerate(new_names.items())}\n",
    "    df.columns = new_names.values()\n",
    "\n",
    "    # Retourne le dataframe nettoyé\n",
    "    return df\n",
    "\n",
    "df = df[~df['TARGET'].isna()] # TARGET=0/1\n",
    "df = fct_clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Secondarysecondaryspecial</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_MAX</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_MEAN</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_MAX</th>\n",
       "      <th>PREV_CODE_REJECT_REASON_SCOFR_MEAN</th>\n",
       "      <th>FLOORSMAX_MODE</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>TR_AGE</th>\n",
       "      <th>NAME_INCOME_TYPE_Pensioner</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Highereducation</th>\n",
       "      <th>ORGANIZATION_TYPE_XNA</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-637.0</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-2120</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1188.0</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-291</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-225.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729567</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-2531</td>\n",
       "      <td>0.555912</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3039.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-19005</td>\n",
       "      <td>-2437</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3038.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3458</td>\n",
       "      <td>0.322738</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAYS_EMPLOYED  EXT_SOURCE_1  EXT_SOURCE_3  DAYS_BIRTH  DAYS_ID_PUBLISH  \\\n",
       "0         -637.0      0.083037      0.139376       -9461            -2120   \n",
       "1        -1188.0      0.311267      0.000000      -16765             -291   \n",
       "2         -225.0      0.000000      0.729567      -19046            -2531   \n",
       "3        -3039.0      0.000000      0.000000      -19005            -2437   \n",
       "4        -3038.0      0.000000      0.000000      -19932            -3458   \n",
       "\n",
       "   EXT_SOURCE_2  CODE_GENDER  NAME_EDUCATION_TYPE_Secondarysecondaryspecial  \\\n",
       "0      0.262949            1                                              1   \n",
       "1      0.622246            0                                              0   \n",
       "2      0.555912            1                                              1   \n",
       "3      0.650442            0                                              1   \n",
       "4      0.322738            1                                              1   \n",
       "\n",
       "   CC_CNT_DRAWINGS_CURRENT_MAX  CC_CNT_DRAWINGS_ATM_CURRENT_MEAN  ...  \\\n",
       "0                          0.0                               0.0  ...   \n",
       "1                          0.0                               0.0  ...   \n",
       "2                          0.0                               0.0  ...   \n",
       "3                          0.0                               0.0  ...   \n",
       "4                          0.0                               0.0  ...   \n",
       "\n",
       "   CC_CNT_DRAWINGS_ATM_CURRENT_MAX  PREV_CODE_REJECT_REASON_SCOFR_MEAN  \\\n",
       "0                              0.0                                 0.0   \n",
       "1                              0.0                                 0.0   \n",
       "2                              0.0                                 0.0   \n",
       "3                              0.0                                 0.0   \n",
       "4                              0.0                                 0.0   \n",
       "\n",
       "   FLOORSMAX_MODE  REG_CITY_NOT_WORK_CITY  FLAG_EMP_PHONE  TR_AGE  \\\n",
       "0          0.0833                       0               1       0   \n",
       "1          0.2917                       0               1       2   \n",
       "2          0.0000                       0               1       3   \n",
       "3          0.0000                       0               1       3   \n",
       "4          0.0000                       1               1       3   \n",
       "\n",
       "   NAME_INCOME_TYPE_Pensioner  NAME_EDUCATION_TYPE_Highereducation  \\\n",
       "0                           0                                    0   \n",
       "1                           0                                    1   \n",
       "2                           0                                    0   \n",
       "3                           0                                    0   \n",
       "4                           0                                    0   \n",
       "\n",
       "   ORGANIZATION_TYPE_XNA  TARGET  \n",
       "0                      0     1.0  \n",
       "1                      0     0.0  \n",
       "2                      0     0.0  \n",
       "3                      0     0.0  \n",
       "4                      0     0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract les 50 features les + importantes selon le meilleur modèle retenu Light_GBM\n",
    "feats_importance = pd.read_csv('df_lgbm_feat_importance.csv')['feat_importance'].values.tolist()\n",
    "df = df[feats_importance + ['TARGET']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension Reference set : (301356, 51)\n",
      "Dimension Current set : (6151, 51)\n"
     ]
    }
   ],
   "source": [
    "# Split Train set/Test set \n",
    "# Pour simuler les data de référence (df_ref) et les data courantes (df_cur)\n",
    "\n",
    "# Split sans stratify pour pouvoir simuler une dérive de la TARGET\n",
    "df_ref, df_cur = train_test_split(df, test_size=0.02, stratify=None, random_state=0)\n",
    "print(f'Dimension Reference set : {df_ref.shape}')\n",
    "print(f'Dimension Current set : {df_cur.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution du REFERENCE set :\n",
      "0.0    277031\n",
      "1.0     24325\n",
      "Name: TARGET, dtype: int64\n",
      "--------------------------------------------------\n",
      "Distribution du CURRENT set :\n",
      "0.0    5651\n",
      "1.0     500\n",
      "Name: TARGET, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check distribution de la Target entre les 2 datasets\n",
    "print(f\"Distribution du REFERENCE set :\\n{df_ref['TARGET'].value_counts()}\")\n",
    "print('-'*50)\n",
    "print(f\"Distribution du CURRENT set :\\n{df_cur['TARGET'].value_counts()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data drift de la TARGET\n",
    "data_drift_report = Report(metrics=[DataDriftPreset(),])\n",
    "data_drift_report.run(reference_data=df_ref[['TARGET']], current_data=df_cur[['TARGET']], column_mapping=None)\n",
    "data_drift_report.save_html('data_drift_target.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data drift des features sans la TARGET\n",
    "df_ref = df_ref.drop('TARGET', axis=1)\n",
    "df_cur = df_cur.drop('TARGET', axis=1)\n",
    "data_drift_report = Report(metrics=[DataDriftPreset(),])\n",
    "data_drift_report.run(reference_data=df_ref, current_data=df_cur, column_mapping=None)\n",
    "data_drift_report.save_html('data_drift_feats.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- On n'observe pas de dérive dans les données (pas de changement de comportement)\n",
    "- C'est normal car ici les données de référence et courantes appartiennent au même dataset (prises au même moment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
